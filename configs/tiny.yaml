# Tiny 10K configuration for testing tokenizer training
# English only with minimal samples for quick testing

total_samples: 100_000
streaming_enabled: true
output_dir: "train-tiny-100k"
temperature: 0.3
min_samples_per_lang: 50_000   # Half of total for single language
max_samples_per_lang: 100_000  # Max matches total samples
vocab_size: 10_000             # Small vocabulary for testing

datasets:
  # English only for tiny testing
  - path: "HuggingFaceFW/fineweb"
    description: "English web data for testing"
    subsets:
      - name: "sample-10BT"
        priority: 5 